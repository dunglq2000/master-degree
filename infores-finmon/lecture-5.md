# Глава 5. Методы автоматической обработки и лексического анализа документальной информации

В основе решения таких задач анализа и синтеза, как индек-сирование, классификация и кластеризация, лежит понятие семан-тического соответствия между текстами, которое в свою очередь сводится к определению «силы» семантической связи между соот-ветствующими терминами. Соответственно, в основе методов ав-томатической обработки документальной информации лежит то свойство, что текст - это ограниченный набор терминов (отдельные слова и словосочетания), образующих в контексте документа се-мантическую систему, представляющую его смысл. В каждой предметной области формируется своя, в той или иной степени устойчивая и динамичная, терминологическая система. В инфор-мационном аспекте (в задачах обработки информационных пото-ков) такую систему могут составлять следующие объекты:

- терминологические таблицы, организованные в виде се-мантических сетей, каждому узлу которых сопоставлен некоторый набор документов;
- тезаурусы и онтологии – сетевые словарные структуры, отражающие парадигматические и синтагматические связи терми-нов в конкретной предметной области;
- классификации, тематические рубрикаторы и др.

Giải pháp cho các vấn đề phân tích và tổng hợp như lập chỉ mục, phân loại và phân cụm dựa trên khái niệm về sự tương ứng ngữ nghĩa giữa các văn bản, từ đó xác định “sức mạnh” của mối liên hệ ngữ nghĩa giữa các thuật ngữ tương ứng. Theo đó, cơ sở của các phương pháp xử lý tự động thông tin tài liệu là đặc tính rằng văn bản là một tập hợp giới hạn các thuật ngữ (từ và cụm từ riêng lẻ) tạo thành một hệ thống ngữ nghĩa trong bối cảnh tài liệu thể hiện ý nghĩa của nó. Mỗi lĩnh vực chủ đề phát triển hệ thống thuật ngữ, ở mức độ này hay mức độ khác, ổn định và năng động. Ở khía cạnh thông tin (trong các nhiệm vụ xử lý luồng thông tin), một hệ thống như vậy có thể bao gồm các đối tượng sau:

- các bảng thuật ngữ được tổ chức dưới dạng mạng ngữ nghĩa, mỗi nút trong đó được liên kết với một bộ tài liệu nhất định;
- từ điển đồng nghĩa và bản thể luận – các cấu trúc từ điển mạng phản ánh các kết nối mô hình và ngữ đoạn của các thuật ngữ trong một lĩnh vực chủ đề cụ thể;
- phân loại, bảng đánh giá theo chủ đề, v.v.

---

В целом можно сказать, что именно терминологические си-стемы позволяют не только идентифицировать информационные объекты хранения и поиска, но и, оценивая динамику изменения терминологической системы, наблюдать и прогнозировать разви-тие (по крайней мере - изменение) предметной области. Количе-ственной мерой при этом будет изменение частот употребления лексики, характерной для этой предметной области.

Nói chung, chúng ta có thể nói rằng chính các hệ thống thuật ngữ không chỉ giúp xác định các đối tượng lưu trữ và truy xuất thông tin mà còn bằng cách đánh giá động lực thay đổi trong hệ thống thuật ngữ, để quan sát và dự đoán sự phát triển (ít nhất là thay đổi) của lĩnh vực chủ đề. Thước đo định lượng trong trường hợp này sẽ là sự thay đổi về tần suất sử dụng vốn từ vựng đặc trưng của môn học này.

## 5.1. Методы выделения информативных терминов

> 5.1. Phương pháp xác định thuật ngữ thông tin

Первой задачей при построении терминологической системы является задача выделения из текстов предметной области отдель-ных слов или словосочетаний, которые для данной предметной об-ласти обозначают ключевые понятия. Для выявления терминов – кандидатов для включения в терминологическую систему применяются модели «взвешивания» и ранжирования терминов. Вычисление веса отдельного термина в рамках информационного массива проводится в соответствии со следующими основными методика-
ми:

Nhiệm vụ đầu tiên khi xây dựng hệ thống thuật ngữ là nhiệm vụ tách khỏi văn bản của một lĩnh vực chủ đề những từ hoặc cụm từ riêng lẻ biểu thị các khái niệm chính của một lĩnh vực chủ đề nhất định. Để xác định các thuật ngữ ứng viên để đưa vào hệ thống thuật ngữ, các mô hình “trọng số” và xếp hạng các thuật ngữ được sử dụng. Việc tính trọng số của một số hạng riêng lẻ trong mảng thông tin được thực hiện theo các phương pháp cơ bản sau:

**TF** (Term Frequency) – в основе методики лежит частота встречаемости термина в документе (или в массиве документов).

TF (Tần suất thuật ngữ) - phương pháp này dựa trên tần suất xuất hiện của một thuật ngữ trong tài liệu (hoặc trong một mảng tài liệu).

---

**TF\*IDF** (Term Frequency*Inverse Document Frequency) – в соответствии с этой методикой вес слова зависит от частоты его появления в конкретном предложении и в документе в целом.

TF\*IDF (Tần số thuật ngữ*Tần số nghịch đảo của tài liệu) - theo kỹ thuật này, trọng số của một từ phụ thuộc vào tần suất xuất hiện của nó trong một câu cụ thể và trong toàn bộ tài liệu.

---

**TL\*TF** (Term Length*Term Frequency) - методика базируется на том, что слова, которые появляются часто, стремятся быть краткими. Такие слова не описывают основную тему документа, т.е. являются стоп-словами. Наоборот, слова, которые появляются редко, стремятся быть длинными.

TL\*TF (Độ dài thuật ngữ*Tần suất thuật ngữ) - kỹ thuật này dựa trên thực tế là các từ xuất hiện thường xuyên có xu hướng ngắn. Những từ như vậy không mô tả chủ đề chính của tài liệu, tức là là những từ dừng lại. Ngược lại, những từ ít xuất hiện thường có xu hướng dài.

---

Рассмотрим некоторые конкретные применения перечисленных методик.

Hãy xem xét một số ứng dụng cụ thể của các kỹ thuật này.

**Мера инверсной частоты термина (TF-методика).** Расчет весовых коэффициентов может быть основан на так называемой мере инверсной частоты термина [Buckley,1986; Salton, 1986], которая задается следующим выражением:

$$w_i = \log \frac{N_0}{F_i}, \quad 0 \leqslant w_i \leqslant \log N_0,$$

где

- $N_0$ - общее число документов информационного массива;
- $F_i$ - частота i-того термина (количество документов массива, содержащих данный термин).

**Thước đo tần số nghịch đảo của một số hạng (phương pháp TF).** Việc tính toán các hệ số trọng số có thể dựa trên cái gọi là phép đo tần số nghịch đảo của một số hạng [Buckley, 1986; Salton, 1986], được tính bằng biểu thức sau:

$$w_i = \log \frac{N_0}{F_i}, \quad 0 \leqslant w_i \leqslant \log N_0,$$

Ở đâu

- $N_0$ - tổng số tài liệu trong mảng thông tin;
- $F_i$ - tần số của số hạng thứ i (số lượng tài liệu mảng chứa số hạng này).

---

Такая мера разбивает все терминологическое пространство на $[\log N_0]$ кластеров со значениями весов $0 \leqslant w_i < 1$, $1 \leqslant w_i < 2$, ..., $[\log N_0] - 1 \leqslant w_i < [\log N_0]$. При этом термины, у которых $F_i = 1$, попадают в последний кластер – кластер самых «тематически точных» терминов, а в первом кластере находятся термины, наиболее общие для информационного массива.

**Мера Чена (TL*TF-методика).** В [Chen, 1997] рассматривается модифицированная мера инверсной частоты, дополненная показателем длины термина:

$$w_i^{ch} = \log L_i + \log \frac{N_0}{F_i},$$

где $L_i$ - количество слов в термине.

Рассмотрим этот весовой показатель с точки зрения структурных свойств терминологической системы:

$$w(d_i) = \log(L_i) + (\log N - \log(F_i))$$

Первое слагаемое отражает степень точности отождествления термина с определенным понятием (успешность угадывания смысла термина, образованного из $l$ слов, по крайней мере, в $l$ раз выше), второе – «специфичность», как величину обратную «общности» в рамках множества возможных значений коллекции из $N$ документов.

В пространстве терминов образуется еще один кластер со значениями весов     1 0 0 log N  w  log N  i , а термины, у которых 1  i F , распределены уже по нескольким кластерам, причем в кластер с номером   1 0 log N  попадают самые длинные словосочетания. Это отражает тот факт, что словосочетания являются более специфичными (менее общими) терминами для информационного массива.

TF*IDF-методика. Методика расчета весов заключается в следующем:

Пусть документ d состоит из m предложений и может быть представлен в виде набора предложений:

d = (s1, s2 ,..., sm ) .

Каждое предложение идентифицируется взвешенным вектором слов, присутствующих в документе

si = (wi1, wi2 ,..., win ) ,

где n -количество слов в документе d .

Вес wij слова j зависит от частоты его появления в конкретном предложении i и во всем наборе предложений (в документе:

где mj - количество предложений, в которых присутствует слово j.

Функция fij частоты появления слова j в предложении i вычисляется следующим образом:

где nij - количество появления слова j в предложении i ;

len(si ) -длина (количество слов) предложения si

Во избежание смещения, вызванного длиной предложения, функция fij нормализована относительно длины предложения.

Неинформативными терминами являются термины мало встречаемые (часто среди них встречаются слова с ошибками) и наиболее встречаемые (кандидаты на новые стоп-слова) в наборе.

Выделение словаря информативных слов проводится на основе граничных значений частот. После определение интервала термины, попадающие в этот интервал, составляют множество информативных терминов (ключевых слов), полученное после этапа статистической обработки.

Приведем еще один способ вычисления веса термина по методике TF*IDF, который не требует информации об отдельных предложениях (интегральная значимость):


 
d
dt
t m
m
n
N
tf idf
2
1
2
1
log 2
,

где

N – количество документов,

nt – количество документов, в который входит термин t,

mdt – число вхождений термина t в документ d,

md = dt
d
maxm .

## 5.2. Статистические меры близости терминов

В общем случае семантические связи отражают качественно различные, как правило, не сводимые друг к другу связи между денотатами. Поэтому, если два термина связаны с некоторым тре-тьим двумя различными видами семантической связи, то сопостав-ление их с целью определить, какой из них «ближе по значению» к третьему (то есть попытка сравнить семантические связи между ними и третьим термином), строго говоря, неправомерно. Семан-тическая связь (в изложенном выше понимании) характеризуется не одним, а несколькими параметрами, и свести эти параметры к одному (семантическому расстоянию) нельзя. Однако необходимо учитывать, что наличие определенного вида связи между терминами иногда свидетельствует о наличии между этими же терминами некоторого другого вида связи. Например, для языка RX-кодов [Скороходько, 1974] наличие се-мантической связи между двумя терминами означает, что в их со-став входит одинаковая характеристика. Если эта характеристика не является термином словаря, то вместо нее можно поставить со-ответствующий семантический код (т. е. развернуть сравниваемые термины). В результате у двух терминов окажутся одинаковыми еще две характеристики (другими словами, если совпадают верши-ны деревьев, то совпадают и подчиненные им поддеревья). Тем са-мым, между данной парой терминов окажется возможным устано-вить по новым характеристикам еще некоторый вид (или виды) се-мантической связи (в частном случае по новым характеристикам устанавливается тот же вид связи).

Таким образом, количественно семантическое расстояние может быть определено как функция от числа семантических со-ставляющих, присущих одновременно обоим словам. Считается, что чем больший удельный вес общих составляющих, тем меньше семантическое расстояние между словами. При полном совпадении семантических составляющих семантическое расстояние равно ну-лю (значения обоих слов тождественны — синонимия). Если, напротив, ни одна семантическая составляющая не совпадает, се-мантическое расстояние считается бесконечно большим (значения слов не имеют ничего общего).

Рассмотрим некоторые подходы, рассматривающие семантическое расстояние между терминами как функцию вычисления меры их близости.

Степень семантической связи. Основная трудность при определении семантического расстояния заключается в том, что отсутствуют точные методы как адекватного описания значений слов в терминах семантических составляющих, так и учета характера связей. Для языка RX-кодов [Скороходько, 1974] в пределах каждого отдельного вида семантической связи можно выделить различные степени этой связи. Степень семантической связи можно определить с помощью следующей формулы, в которой учитываются основные из перечисленных выше параметров:

2
0   
 i D ,

где D — степень семантической связи;

i  - удельный вес совпавшей характеристики в термине запроса;

0  - удельный вес совпавшей характеристики в термине объекта.

Удельный вес характеристики в термине определяе тся по формуле:



 m
k
k v
v
1


где v - абсолютный вес характеристики в термине, v=s/2p ;

т – число конечных вершин в дереве термина (одной из которых является совпавшая вершина);

р - разряд характеристики;

s - категория характеристики (0 - общеупотребительное понятие, 2 - понятие смежной области, 3 - специальное понятие данной области).

Семантическое расстояние пары терминов, основанное на семантических множителях. Другой метод([Ратцева, 1966]), учитывающий семантическую значимость терминов, представленных в пространстве смысловых категорий (семантических составляющих), определяет семантическое расстояние пары терминов как

I J
IJ
n n
n

1 
,

где nIJ – число общих семантических множителей для терминов di, dj;

(nI + nJ) - общее число семантических множителей терминов di, dj , а в качестве семантических множителей используются рубрики тезауруса, в которые входит термин.

Эта мера позволяет устанавливать силу семантической связи между словами, но не ее характер. Действительно, может оказаться, что семантическое расстояние между словами «стул» и «кресло» равно расстоянию между словами «стул» и «мебель». Однако ясно, что характер семантической связи между этими двумя парами слов различный: в первом случае слова выражают смежные понятия, во втором — вид и род.

Меры сходства. Рассмотренные выше меры семантической связи основаны на использовании характеристик, которые свойственны языкам со сложной грамматикой и практически отсутствуют в ИПЯ современных систем. При этом следует отметить первые реализации автоматического извлечения некоторой апостериорной семантической информации (установления ассоциативных связей между терминами) с помощью мер сходства (коэффициентов ассоциаций), широко используемых в методах автоматической классификации и кластерного анализа [Rijsbergen, 1975]. Наиболее известными мерами являются:

IJ Ij iJ
IJ
n n n
n
 
 1  (Jaccard);
d
n nIJ ij 
 2  (Soral);
d
nIJ  3  (Rao);
172
n ( n n )
n
IJ Ij iJ
IJ
 

2 2
2
4  (Dice);
iJ Ij
IJ ij
d n n
n n
 

 5  (Tanimoto);

где nIЈ – число совместных появлений di и dj в документах
массива;

nij – число совместных непоявлений di и dj;

nІj – число документов, содержащих di и не содержащих dj;

niЈ – число документов, содержащих dj и не содержащих di;

nІ = nIЈ + nІj – общее число появлений di;

d = |D| – размер словаря.

Дистрибутивно-статистический анализ. В основу дистрибутивно-статистического анализа [Маршакова, 1977; Шайкевич, 1976] положена гипотеза о том, что сила связи пары слов определяется величиной отклонения эмпирических данных о совместной их встречаемости от теоретических (математическое ожидание) в предположении о независимости появления этих слов в тексте. Хорошей иллюстрацией является работа [Москович, 1971], в которой метод дистрибутивно-статистического анализа используется при построении тезауруса для установления семантических связей, причем сила парадигматических связей между di и dj (понимаемых как обобщение синтагматических) определяется как

  
k
ij ij ik ik jk jk P S lg( S m S m ) ,

где Pij – сила парадигматической связи между di и dj;

Sij – сила синтагматической связи;

mij – математическое ожидание совместной встречаемости di и dj .

Данный подход позволил успешно выделить устойчивые семантически-регулярные словосочетания, однако используемая классификация выявленных связей достаточно условна. Парадигматические связи, понимаемые как обобщение синтагматических, в тексте обычно явно не присутствуют, а выделяются априорно в понятийной структуре языка при его разработке.

Другим показателем является мера парадигматической близости терминов В.Джулиано:

k l
D
i l
ki li
k l f * f
f
f * f
n*
A

 1

где n – объем выборки (число документов),

fij – число документов, в которых вместе встретились i-й и j-й термины, fk – число документов, в которых встретился k-й термин.

Поскольку семантические связи внутри каждого конкретного текста определяются автором в значительной степени субъективно, то для уверенности в правильности установления ассоциативных отношений необходимо исследовать значительные массивы документов. Причем, на оригинальных текстах дистрибутивно-статистический анализ позволяет установить лишь синтагматические отношения, поскольку слова, связанные парадигматическими отношениями, встречаются вместе крайне редко (например, в определениях). Поэтому в работах [Плотников, 1975; Покрас, 1971] для определения меры близости этих слов предлагается использовать толковые и/или энциклопедические словари, что требует дополнительных затрат при автоматизации соответствующих проце-
дур.

Несколько более детальный подход к выявлению устойчивых
структурных связей с оцениванием связи пары терминов в цепочке,
в иерархической и замещаемой структурах приведен в [Горькова,
1979].

Несимметричный коэффициент подобия. Приведенные
оценки меры семантической близости строятся только на данных о
частотах употребления, никак не учитывая места этих терминов в
понятийной структуре языка. Более того, почти все коэффициенты
ассоциаций симметричны, что не всегда выполняется в языковых
системах, по крайней мере, для родо-видовых отношений.
Предложенный в [Сэлтон, 1973] несимметричный коэффици-
ент подобия

 



k
i
k
k
j
k
i
k
ij V
V V
C
min ,
использует K-мерные вектора свойств V
i
, V
j

, представляющие
информативность и специфичность терминов di и dj соответственно
с точки зрения удобств их использования при индексировании. Та-
кой коэффициент, по всей видимости, лишенный указанных ранее
недостатков, использует, однако, субъективно-задаваемые векторы
свойств.

## 5.3. Методы классификации и кластеризации документов

Если рассмотренные выше методы выделения в тексте ин-
формативных терминов ассоциируются с задачами анализа, то ме-
тоды классификации и кластеризации связываются с задачами син-
теза – построения системы классов документов или терминов. Хотя
необходимо отметить, что методы классификации широко исполь-
зуются на этапе предобработки для определение тематики доку-
мента и приписывания ему соответствующего шифра.

Приведем обзор методов, осуществляющих кластеризацию
или классификацию документов.

Технология построения иерархической структуры папок.

Суть технологии заключается в автоматическом распределении
множества объектов – текстовых документов по папкам. Папки
имеют иерархическую структуру, что дает возможность всё более и
более сужать область просмотра документов. Подсчёт коэффици-
ентов близости для всего объёма документов выполняется по мере
поступления новых документов в коллекцию.
Например, в поисковом сервере NorthernLight иерархия па-
пок содержит около 20000 элементов. Однако, поскольку набор
папок построен вручную и определен заранее, технология обладает
следующими недостатками:

- иерархия папок имеет общий характер, поэтому не может
быть использована, например, для поиска в специализиро-
ванных базах данных;
- структуру папок необходимо периодически обновлять.
Методы факторного анализа. В основе методов лежат принципы выявление латентной структуры изучаемых явлений или объектов.

Пространство терминов рассматривается как пространство элементарных признаков (факторов). Документы, содержащие се-мантически близкие термины, группируются в определённых ме-стах пространства терминов. Фактор - это некая семантическая сущность, которая может не иметь определённого названия. После определения числа и параметров факторов происходит отображе-ние множества документов на пространство факторов.

Задачей факторного анализа является выделение главных факторов из пространства элементарных. В большинстве случаев задача нахождения главных факторов решается с помощью Метода Главных Компонентов [Дубров, 1998]. Количество главных факто-ров выбирают существенно меньшим, чем количество элементар-ных, редуцируя таким образом пространство, на которое происхо-дит отображение документов. Определение количества главных факторов и конфигурации их в пространстве являются основными проблемами факторного анализа.

Метод факторного анализа позволяет успешно преодолевать проблемы синонимии (когда одно и то же понятие может быть описано разными словами – синонимами) и омонимии (когда одно слово может иметь разные смыслы в разных контекстах), основы-ваясь только на статистической информации о множестве докумен-тов/терминов.

Метод использует статистическую информацию о множестве документов/терминов и в общем случае не нуждается в предвари-тельной настройке на специфический набор документов (не требу-ет обучения). Однако некоторые реализации метода могут быть как обучаемыми, так и необучаемыми. Практически обучение заключа-ется в фиксировании предопределённого количества центроидов кластеров (центроид кластера - вектор, который вычисляется как среднее арифметическое векторов всех документов кластера), а классификация заключается в отнесении документа к кластеру, расстояние до центроида которого наименьшее.

Основными недостатками метода можно назвать следующие:

- большое количество вычислений при реализации алго-ритма;
- отсутствие подходящего наименования для вычисленных факторов;
- полученные кластеры не могут пересекаться.

Метод суффиксных деревьев. Суффиксные деревья изна-чально были разработаны для быстрого поиска подстрок. Суф-фиксное дерево – это дерево, содержащее все суффиксы рассмат-риваемой строки. Ветви дерева обозначаются буквами или букво-сочетаниями, которые являются частями суффиксов строки. Суф-фикс, соответствующий определённой вершине, можно получить путем объединения всех букв, которые находятся на ребрах дерева, начиная от корневой вершины и заканчивая заданной.

Суффиксное дерево кластеризации строится из слов и фраз входных документов, т.е. единицей, находящейся на ребре дерева, является слово или словосочетание. Построение дерева осуществ-ляется поэтапно. Сначала документы подвергаются предваритель-ной обработке - отчистка от пунктуации, приведение слов в начальную форму (с помощью, например, алгоритмов морфологи-ческого анализа) и т.д. Затем для набора документов строится де-рево. Каждой вершине такого дерева соответствует фраза. Её мож-но получить, объединив все слова/словосочетания, находящиеся на рёбрах на пути от корня дерева к данной вершине дерева. В тех вершинах дерева, которые имеют потомков, находятся ссылки на документы, в которых встречается фраза, соответствующая вер-шине. Множества документов, на которые указывают эти ссылки, образуют базовые кластеры.

К достоинствам метода можно отнести высокую скорость ра-боты (по времени и занимаемой памяти дерево строится пропорци-онально количеству документов), наглядность представления ре-зультатов (общие фрагменты текстов и фраз выступают в качестве названия кластеров). Алгоритм не нуждается в обучении и задании порога срабатывания, а также допускает пересечение кластеров.

Недостатки метода:

- не используется уже имеющаяся информация о значения близости документов или весах слов/словосочетаний;
- не выявляется семантика документов, присутствующая не только на текстовом уровне;
- не решаются проблемы синонимии и омонимии.

Методы кластерного анализа. Общая суть этих методов за-ключается в выполнении следующих шагов:

1. Вычисление значений близости между документами и формирование матрицы близости.
2. Отнесение каждого документа в свой отдельный кластер.
3. Объединение в один кластер наиболее близких пар доку-ментов.
4. Обновление матрицы близости путем удаления колонок и строк для документов, которые были объединены, и перерасчет матрицы близости.
5. Переход на шаг 3 до тех пор, пока не выполнится крите-рий останова.

Достоинством методов является использование матрицы бли-зости документов, а также тот факт, что алгоритмы методов не нуждаются в обучении;

Основные недостатки методов:

- необходимо задавать порог – максимальное количество документов в кластере;
- для получения хороших результатов кластеризации значе-ния близости между парами документов должны быть упорядочены;
- кластеры не пересекаются.

Метод стабилизирования центроидов кластеров. Основ-ной характеристикой кластера является его ценроид и вся работа алгоритма направлена на стабилизирование или, в лучшем случае, полное прекращение изменения центроида кластера. Алгоритм ме-тода состоит из следующих шагов:

1) Выбираются начальные центроиды для множества доку-ментов. Существует несколько методик выбора центроидов. По одной из них, например, из множества документов случайным об-разом выбираются k документов, где k равно требуемому числу кластеров и на первом шаге эти документы становятся центроида-ми кластеров.
178
2) Все документы множества распределяются по кластерам. Документ попадает только в один кластер - тот, у которого метрика близости центроида и документа имеет наибольшее значение.
3) Пересчитываются центроиды кластеров, исходя из нового множества документов в каждом кластере. Если центроид кластера изменился, то цикл вычислений повторяется с пункта 2. Иначе, ес-ли центроид стабилизировался в некоторой окрестности или пол-ностью, процесс кластеризации завершается.
Метод характеризуется линейной скоростью работы алго-ритма, использует значения весовых коэффициентов терминов, не нуждается в обучении.

Недостатки метода:

- требует задания количества кластеров, как минимум на начальных этапах – до использования априорной инфор-мации;
- в том случае, когда центроиды кластеров выбираются случайным образом, результаты, получаемые над одной и той же выборкой документов, могут отличаться;
- кластеры не пересекаются.

Нейронная сеть Кохонена. Нейронная сеть Кохонена вы-полняет задачу кластеризации входных данных и обучается без учителя. Метод разработан для отображения многомерных данных на двумерную плоскость. Сети Кохонена называют также тополо-гическими картами.

Для обучения сети алгоритм Кохонена использует информа-цию о предыдущем шаге обучения, поэтому нельзя чётко говорить о скорости обучения такой сети.

Параметры кластеров при кластеризации с помощью сети Кохонена формируются в результате специального алгоритма обу-чения сети, применяемого к множеству документов. Если сеть не может выделить объект в определённый кластер, то имеет место факт зарождения нового кластера данных.

Метод прост в обучении и обеспечивает наглядность пред-ставления результатов кластеризации. В качестве входных данных для сети используются расстояния между документами, т.е. значе-ния матрицы близости. Полученные кластеры могут пересекаться.
Недостатки метода:

- необходимость обучения сети для каждого нового множе-ства документов;
- процесс обучения требует фиксирования числа кластеров и набора обучающих данных.

Методы, основанные на гипертекстовых ссылках. Одним из наиболее часто используемых форматов для представления до-кументов в Internet является HTML, который позволяет создавать документы со ссылками. Использование гиперссылок с одних Web-страниц на другие позволяет реализовать достаточно эффективную навигацию. Но, кроме этого, анализ взаимосвязей документов при индексировании их поисковыми машинами позволяет обеспечить относительно высокую точность поиска. Это достигается за счет использования алгоритма ранжирования документов в соответ-ствии с индексом их «цитирования», который можно оценить чис-лом ссылок, ведущих к данному документу из других. Наиболее известным применением и развитием индекса ци-тирования является PageRank, который рекурсивно определяет важность Web-страницы на основе информации о страницах, ссы-лающихся на неё. Вероятностная модель подсчета ранга Web-страницы PageRank рассматривает следующий процесс: пользова-тель открывает случайную Web-страницу, с которой переходит по случайно выбранной гиперссылке на другую страницу, где он сно-ва активизирует случайную гиперссылку и так далее. Иногда поль-зователь переходит на случайную Web-страницу не по ссылке, а набрав URL вручную. В этом случае вероятность того, что «сколь-зящий» пользователь перейдет на некоторую определенную Web-страницу и будет ее рангом, который тем выше, чем большее число страниц ссылается на нее. Алгоритм, учитывающий связь с запросом (локальная «попу-лярность») — HITS (hyperlink induced topic search) выбирает под-граф из гипертекстовой сети документов, отвечающих запросу. Из этого подграфа выделяются два вида узлов: «первоисточники» - страницы, на которые ведут ссылки с достаточно большого числа других страниц, и страницы-«посредники», которые содержат в основном ссылки на страницы, соответствующие запросу. Под-множество наиболее «популярных» страниц строится путем рас-ширения множества найденных по запросу страниц за счет добавления страниц, связанных с ними через заданное число ссылок. При этом для каждого документа вычисляется его значимость как первоисточника и как посредника. Другим путем является категоризация – классификация найденных документов в соответствии с некоторой схемой пред-метных категорий. Соответственно, если пользователь указывает интересующую его категорию, документы могут быть ранжирова-ны в контексте именно этого подмножества. Однако эти модели не учитывают динамику развития WWW, так как в момент индексирования анализируется граф фиксирован-ной структуры. Во-вторых, взвешивание и категоризация хорошо работают для сложившихся предметных областей (и, соответствен-но, с предопределенной системой категорий) и не учитывают ин-дивидуальностей конкретного пользователя. Поэтому, например, пионерская статья или запрос, открывающие новое направление, скорее всего будут иметь низкий вес и не попадут в выдачу первых страниц.
## 5.4. Автоматическое реферирование и аннотирование

Программы автоматизированной обработки текстов, реали-зующие индексирование, реферирование и другие формы инфор-мационного анализа и синтеза вторичных документов, имеют исто-рию, сопоставимую с историей развития вычислительных машин и автоматизированных систем управления. Именно на основании вторичных документов, существенно меньших по объему по отно-шению к исходному тексту, пользователи могут составить более или менее обоснованное представление о содержании первичного документа, затратив на это значительно меньше усилий в сравне-нии с его полным прочтением. Но существенно более полезной та-кая форма представления содержания оказывается для автоматизи-рованного поиска. Содержание практически любого документа сводится к форме, в которой основные объекты, методы и резуль-таты представляются компактными не избыточными выражениями, к тому же легко сводимыми к перечислению, в том числе нормализованных, терминов и отношений1. Это, как отмечалось ранее, поз-воляет, с одной стороны, реализовать эффективные алгоритмы по-иска, а с другой – за счет избыточности выдачи дает уверенность пользователю в том, что он, обращаясь к системе с запросом из трех–четырех слов, может достигать достаточной полноты выдачи даже в случае, когда информационная потребность представляет узкую тематику. Задачи автоматического анализа и синтеза неоднофразовых текстов связаны с решением следующих проблем:

1. Предложения текста могут содержать элементы, значение которых определяется элементами других предложений.
2. Для определения общего смысла текста существенен не только смысл отдельных предложений, но и отношения между ними.
3. Текст имеет такие неотъемлемые характеристики, как те-ма и композиционная структура, что существенно при определении смысла не только отдельных фрагментов, но и всего текста в целом.

На сегодняшний день сложились два направления анализа первичных документов — квазиреферирование и синтез краткого содержания (квазианнотирование).

Квазиреферирование основано на экстрагировании фрагмен-тов документов, т.е. выделении наиболее информативных фраз. Квазианнотирование основывается на выделении из текстов с помощью методов искусственного интеллекта наиболее суще-ственных семантических единиц и порождении нового текста, пе-речисляющего основные объекты (цели, средства, положения, ис-пользованные или разработанные методы, результаты и т.д.) пер-вичного документа.

**Алгоритмы квазиреферирования**. Квазиреферирование сводится к извлечению из документов некоторых минимальных фрагментов текста, в максимальной степени связанных с основными положениями документа. Создание квазиреферата, таким обра-зом, представляет собой соединение выбранных фрагментов. Выделяют три основных направления, применяемые для ква-зиреферирования:

- Индикаторные методы, основанные на оценке элементов текста исходя из наличия в них специальных слов и сло-восочетаний
- так называемых маркеров важности («в заключение», «было отмечено, что...» и пр.), характеризу-ющих их смысловую значимость.
- Позиционные методы, опирающиеся на предположение о том, что информативность элемента текста находится в зависимости от его позиции в документе.
- Статистические методы, основанные на оценке информа-тивности различных фрагментов текста по частотным по-казателям, таким, как расположение этого блока в ориги-нале, частота появления терминов в тексте, частота ис-пользования терминов в ключевых предложениях и т.д.

Позиционные методы опираются на предположение, что в разных структурных составляющих документа вероятность при-сутствия терминов, соответствующих основным составляющим смысла, различна. Согласно исследованиям [Иванкин, 1975] наибо-лее вероятно ключевые термины встречаются в Заглавиях (0,33), заголовках (0,22), первом предложении (0,18), последнем предло-жении (0,04). Определение веса фрагментов исходного текста в статисти-ческих методах выполняется по алгоритмам, разработанным еще в 60-70-е годы и ставшим уже традиционными. Общий вес текстово-го блока на этом этапе вычисляется по формуле: W= L + K + S , где L определяется расположением блока в исходном тексте и зависит от того, где появляется данный фрагмент — в начале, в середине или в конце, а также используется ли он в ключевых раз-делах текста, например, в заключении. К учитывает использование блока в «резюмирующих» конструкциях типа «в заключение», «в данной статье», «результатом является» и т.п.. Статистический вес текстового блока S вычисляется как нормированная по длине этого блока сумма весов входящих в него терминов — слов и словосочетаний. Блоки с наивысшими весовыми коэффициентами и будут включены в текст квазиреферата. Алгоритмы квазианнотирования. Большинство алгорит-мов квазианнотирования включают три основных этапа: анализ текста, определение весомых фрагментов (предложений или целых абзацев) и формирование вывода. Первый этап начинается с выделения из исходного текста лексических единиц (слов или словосочетаний) и их взвешивания. Сначала выполняется выделение из исходного текста всех лексиче-ских единиц и построение из них словарного массива. При этом каждой лексической единице присваивается коэффициент, завися-щий от ее расположения в исходном тексте. Затем выполняется их нормализация. Для выполнения последующего семантического анализа каждой словоформе ставятся в соответствие значения грамматических категорий (род, падеж, число). На этом этапе с по-мощью стоп-словаря выполняется удаление из словарного массива слов, не несущих явной смысловой нагрузки. Для этого каждой из лексических единиц присваивается весовой коэффициент, который определяется как результат учета нескольких составляющих: ча-стоты появления, тематического словаря (определяемого, напри-мер, тематикой запроса пользователя) и «плюс-словаря», включа-ющего наиболее важную лексику общего назначения. Последний этап формирования массива лексических единиц заключается в выборе некоторого ограниченного количества самых весомых терминов. Полученный массив лексических единиц, кроме задачи автореферирования, в дальнейшем может быть использован и при различных лингвистических исследованиях текста.

Автореферирование на основе семантических методов. Подход, опирающийся на методы искусственного интеллекта, ис-ходит из предположения, что если удается определить семантику текста, то аннотация будет более качественной. Используемые при этом базы знаний должны постоянно поддерживаться в актуальном состоянии и сопровождаться экспертами [Griffiths, 1997]. Для под-готовки рефератов при таком подходе требуются мощные инфор-мационные ресурсы, обеспечивающих обработку текстов на есте-ственных языках, в том числе базы грамматических правил и словари для синтаксического разбора естественно-языковых кон-струкций. Для реализации этого метода нужны многочисленные необходимые для анализа и определения наиболее важной инфор-мации справочники, которые отражают понятия, ориентированные на предметные области. В отличие от частотно-лингвистических методов, обеспечи-вающих квазиреферирование, подход, основанный на базах знаний, опирается на автоматизированный качественный контент-анализ, состоящий, как правило, из трех основных этапов. Первый — све-дение исходной текстовой информации к заданному числу фраг-ментов – смысловых единиц. На втором этапе производится поиск регулярных связей между ними, после чего наступает третий этап — формирование выводов и обобщений. Такая структурная анно-тация представляет содержание текста в виде совокупности кон-цептуально связанных единиц значения. Семантические методы формирования рефератов-изложений предполагают два основных подхода: метод синтаксического раз-бора предложений и методы, опирающиеся на синтез семантиче-ской структуры текста. В первом случае используются деревья разбора текста. Вто-рой подход основывается на системах искусственного интеллекта, в которых на этапе анализа также выполняется синтаксический разбор текста, но синтаксические деревья не порождаются. В этом случае формируются семантические структуры, которые накапли-ваются в базе знаний и затем объединяются путем слияния графов. В результате преобразования формируется концептуальная струк-тура текста — аннотация, т.е. семантически значимые «выжимки» из исходного текста.

## 5.5. Автоматическое построение онтологий

Автоматическое построение онтологий на основе представлен-ных на естественном языке текстов, т.е. выявление отношений между выделенными в тексте понятиями (сущностями), основыва-ется на преобразовании лингвистических отношений в функцио-нальные. При этом набор типовых, так называемых функциональ-ных, связей для ПрО может быть типизирован и обычно ограничен.

Претенденты на знак, представляющий информационный образ, выявляются с учетом понятийной и терминологической си-стем в следующем порядке.

На первом шаге знаки-термины терминологического уровня выделяются с помощью статистических и лингвистических проце-дур при обработке текста. На следующем шаге для знаков-терминов определяются тождественные знаки-понятия в системе понятийной. Если тождественное понятие найдено, для соответ-ствующего знака-термина выполняется переход на терминологиче-ский уровень для инициирования процедуры уточнения понятия. Эта процедура реализует попытку построить на базе понятия сло-восочетание, характеризующее будущий информационный образ более точно. Если знаку-термину не нашлось соответствующего понятия, он, в зависимости от морфологических признаков, либо исключается из рассмотрения, либо помечается как знак, который обозначает потенциально новое для анализируемой ПрО понятие и также в последствии поступает на процедуру уточнения понятия.

Словосочетания, полученные в результате работы процеду-ры уточнения понятий, предлагается рассматривать как потенци-альные знаки, представляющие информационные образы объектов функциональной системы онтологии.

Вне зависимости от способа получения построенные слово-сочетания обозначают либо устойчивые понятия ПрО, либо потен-циально новые понятия для рассматриваемой ПрО и, в свою оче-редь, соответствуют образам объектов ПрО. При этом потенциаль-но новые понятия могут действительно оказаться новыми понятия-ми для анализируемой ПрО, могут являться синонимами суще-ствующих общепринятых понятий, могут не являться понятиями (неустойчивые словосочетания или ошибочные конструкции). На основании экспертного подтверждения новые понятия могут быть добавлены в сложившуюся систему понятий. Окончательный отбор терминов, которые войдут в семантический образ документа, про-исходит с учетом их статистических весов в документе.

Предлагается два способа уточнения понятий:

- с учетом пропозициональной структуры предложения;
- на основании морфологических свойств слов естественно-го языка.

Следует отметить, что учет пропозициональной структуры предложений позволяет уменьшить вероятность некорректных конструкций.

Уточнение понятий с учетом пропозициональной структуры предложения

Пропозициональная структура предложения представляется семантической сетью, в вершинах которой находятся лексические единицы (знаки-термины), а дуги соответствуют лингвистическим отношениям [13].

Лингвистические отношения между словами предложено объединять в кластеры по близости значений этих отношений и далее рассматривать кластеры отношений сужения/расширения объема понятий.

Построение словосочетаний (терминов-знаков), уточняю-щих понятия, полученные на основании понятийной системы, а также потенциально новые понятия для рассматриваемой ПрО, происходит на знаковом уровне за счет объединения слов есте-ственного языка, связанных лингвистическими отношениями из кластеров отношений сужения/расширения объема понятий.

На рис. 1 приведена семантическая сеть предложения «Вы-сокотемпературный слоистый сверхпроводник с дефектами в сме-шанном состоянии представляет собой сложную систему с боль-шим числом степеней свободы» 2.

Рис. 1. Пример семантической сети предложения

Термины «высокотемпературный слоистый сверхпровод-ник», «сложная система» и «большое число степеней свободы» мо-гут быть получены на основании терминов тезауруса «сверхпро-водник», «система» и «степени свободы» в результате объединения со словами, связанными с ними лингвистическими отношениями из группы отношений сужения объема понятий: ПРИЗНАК (PROPERT) и ПАРАМЕТР (PARAM).

Уточнение понятий на основании морфологических свойств слов

Для понятий понятийной системы или потенциально новых предлагается строить субстантивные словосочетания, в которых главенствующее слово объединяется со всеми своими зависимыми на основании его морфологических свойств. Полученные словосо-четания являются именами понятий и обозначают классы объектов предметной области, отраженной в анализируемом тексте.

Например, термин «пиннинг магнитных вихрей» может быть получен путем уточнения тезаурусного понятия «магнитные вихри», а термины «внешнее магнитное поле» и «неоднородное магнитное поле» - в результате уточнения термина тезауруса «маг-нитные поля». Термин «потенциал вихря собственного поля транс-портного тока» может быть получен в результате уточнения и объединения тезаурусных понятий «потенциал», «вихри», «поле» и «ток».

Формирование функциональных отношений

Связывание знаков, представляющих информационные об-
разы объектов, функциональными отношениями (в зависимости от
требований к точности установления связей) предлагается прово-
дить либо на основании лингвистических отношений, либо на ос-
нове «сигнальных» конструкций, задаваемых языком шаблонов.
Построение функциональных отношений на основе
лингвистических

Согласно [6, 13] действия и их участники в тексте обозна-
чаются лексическими единицами, образующими пропозициональ-
ную структуру предложений. Семантический предикат обладает
свойством подчинять себе некоторые семантические актанты ситу-
ации, выражаемой (вербализуемой) данным предикатом, а бинар-
ные связи между предикатом и каждым его актантом (участником
ситуации) представляют собой лингвистические отношения.
С другой стороны, предложение естественного языка как
конструктивный знак соотносится с описываемой им мыслимой
ситуацией как своим денотатом (примером могут служить класси-
фикации – УДК, ГРНТИ и т.п.), т.е. представляет фрагмент дей-
ствительности не просто совокупностью отдельных объектов ПрО,
а их системой. Таким образом, объекты ПрО могут квалифициро-
ваться как участники ситуации (элементы взаимодействия), свя-
занные неким (ситуативным) отношением и выполняющие в рам-
ках взаимодействия определенную функцию.

То есть, переход от лингвистических отношений к функци-
ональным может быть описан нечеткой бинарной функцией соот-
ветствия:

f : LP, где L – множество лингвистических отношений, P – множество функциональных отношений.

Функция f представляет собой набор формализованных
правил соответствия лингвистических отношений функциональ-
ным.

Например, функциональное отношение «является услови-ем» в семантической сети, приведенной на рис. 1, для лингвистиче-ского отношения ЛОКАЛИЗАЦИЯ (LOK) определено на основа-нии следующего правила:

Пусть Р – предикат, X, Y – актанты предиката Р (отдельные слова или главенствующие слова в словосочетаниях). Если (R(X,P) = SUB) и (R(Y,P) = LOK), то (Y ‘является условием’ X) , что позво-ляет в результате построить отношение между информационными образами «высокотемпературный слоистый сверхпроводник» и «смешанное состояние». Слова «сверхпроводник» и «состояние» являются главенствующими словами в соответствующих словосо-четаниях.

Построение функциональных отношений с помощью шаблонов «сигнальных» конструкций

Построение функциональных отношений без учета лингви-стических происходит посредством сравнения элементов текста с шаблонами «сигнальных» конструкций, указывающих на наличие функционального отношения определенного типа между парой терминов, смежных с сигнальной конструкцией. Шаблон определя-ет состав «сигнальной» конструкции (термины, слова, числа, знаки препинания), взаиморасположение элементов «сигнальной» кон-струкции в тексте, их грамматические признаки.

Общий вид синтаксиса записи шаблонов «сигнальных» конструкций следующий (в расширенной БНФ):

template = “RELATION[”, relation parameters, “](”, signal construc-tion, “)”, [ “;SOURCE”, source parameters], [“;TARGET”, target pa-rameters];
После служебного слова RELATION перечислением зада-ются параметры отношения, среди которых обязательным является имя отношения (необязательные, например, порядок следования слов и максимальный радиус поиска слов). В круглых скобках по-следовательностью символьных строк записывается «сигнальная» конструкция.
За служебными словами SOURCE и TARGET в квадратных скобках могут следовать параметры, определяющие требования к обоим понятиям (источнику и цели будущего функционального отношения), связываемым отношением (например, число, падеж и т.п.).
Рассмотрим предложение:

«В итоге именно поведение вихревой системы и её взаимо-действие с дефектной структурой сверхпроводника оказывает вли-яние на транспортные характеристики высокотемпературных сверхпроводников».

Способ уточнения понятий без учета пропозициональной структуры предложения дает следующие субстантивные словосо-четания:

- «поведение вихревой системы» - на основании слов «по-ведение» и «система», входящих в состав тезаурусных понятий;
- «взаимодействие вихревой системы» - в результате рас-крытия анафорической ссылки, выраженной личным ме-стоимением «её» и уточнения понятия «вихревой систе-мы»;
- «дефектная структура сверхпроводника» - на основании слов «сверхпроводники» и «структура», входящих в со-став тезаурусных понятий;
- «транспортные характеристики высокотемпературных сверхпроводников» - на основании слов «транспорт-ные», «характеристики», «высокотемпературные» и «сверхпроводники», входящих в состав тезаурусных по-нятий.

Шаблон сигнальной конструкции «влияние на», имеющий вид

RELATION\[N:Является причиной\]\('влияние' 'на'\);SOURCE\[П:им\];TARGET,
с параметром, задающим морфологический признак терми-на –– именительный падеж позволяет выделить функциональное отношение «является причиной».

На основании шаблона сигнальной конструкции «с», име-ющего вид

RELATION\[N:Является объектом,DIR:reverse,THRESOLD:2\]\('с'\);SOURCE;TARGET ,

в котором задан параметр расстояния между сигнальной конструкцией и терминами – источником и целью будущего функ-ционального отношения (не более 2 слов), определяется функцио-нальное отношение «является объектом».

После выявления функциональных отношений могут быть построены следующие конструкции:

Рис. 2. Фрагмент графа онтологического представления
Объединение полученных фрагментов функционального уровня на основании тождества вершин позволяет получить онто-логическое представление рассматриваемой ПрО, т.е. представле-ние конкретной ситуации в предметной области, выраженное лек-сическими единицами (знаками).
